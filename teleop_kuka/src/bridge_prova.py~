#!/usr/bin/python

import roslib
import rospy
import cv2
import cv2.cv as cv
import sys
from std_msgs.msg import String
from sensor_msgs.msg import Image, RegionOfInterest, CameraInfo
from cv_bridge import CvBridge, CvBridgeError
import time
import numpy as np
import imutils
import tf

blueLower = (110, 50, 50)
blueUpper = (130, 255, 255)

class cvBridgeDemo():
    def __init__(self):
        
        rospy.init_node("blob_detection")
        rospy.on_shutdown(self.cleanup)
        cv.NamedWindow("RGB Image", cv.CV_WINDOW_NORMAL)
        cv.MoveWindow("RGB Image", 25, 75)
	cv.NamedWindow("Depth Image", cv.CV_WINDOW_NORMAL)
	cv.MoveWindow("Depth Image", 25, 350)
        
        
        self.bridge = CvBridge()
        self.image_sub = rospy.Subscriber("/kinect/rgbimage/image_raw", Image, self.image_callback)
	self.image_sub = rospy.Subscriber("/kinect/depthimage/image", Image, self.depth_callback)
        
        rospy.loginfo("Waiting for image topics...")

    def image_callback(self, ros_image):
        try:
            frame = self.bridge.imgmsg_to_cv2(ros_image, "bgr8")
	    frame = cv2.resize(frame, (320, 240)) 
        except CvBridgeError, e:
            print e
        
        frame = np.array(frame, dtype=np.uint8)
        
        display_image = self.process_image(frame)
                       
        cv2.imshow("RGB Image", display_image)
        
        self.keystroke = cv.WaitKey(5)
        if 32 <= self.keystroke and self.keystroke < 128:
            cc = chr(self.keystroke).lower()
            if cc == 'q':
                rospy.signal_shutdown("User hit q key to quit.")
                
            
    def process_image(self, frame):
         hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
   	 mask = cv2.inRange(hsv, blueLower, blueUpper)
         mask = cv2.erode(mask, None, iterations=2)
   	 mask = cv2.dilate(mask, None, iterations=2)

    	 cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]
    	 center = None

    	 if len(cnts) > 0:
		c = max(cnts, key=cv2.contourArea)
		((x, y), radius) = cv2.minEnclosingCircle(c)
		M = cv2.moments(c)
		center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))

		if radius > 2:
			cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)
			cv2.circle(frame, center, 5, (0, 0, 255), -1)
			self.u = int(M["m10"] / M["m00"])
			self.v = int(M["m01"] / M["m00"])


	 
         return frame

    
    def depth_callback(self, ros_image):
	try:
		depth_image = self.bridge.imgmsg_to_cv2(ros_image,"passthrough")
		depth_image = np.array(depth_image, dtype=np.float32)
		depth_image = cv2.flip(depth_image, 0)
		image = cv2.resize(depth_image, (320, 240)) 
		
        except CvBridgeError, e:
            	print e
		
	depth_display_image = self.process_depth_image(image)
	cv2.imshow("Depth Image", depth_display_image)	


    def process_depth_image(self, frame):
	px = (self.u,self.v)
	cv2.circle(frame, px, 5, (0, 0, 255), 2)
	depth = frame.item(self.u,self.v)
	print(px,depth)

	return frame


    def cleanup(self):
        print "Shutting down vision node."
        cv2.destroyAllWindows()   
   
 
def main(args):       
    try:
        cvBridgeDemo()
        rospy.spin()
    except KeyboardInterrupt:
        print "Shutting down vision node."
        cv.DestroyAllWindows()

if __name__ == '__main__':
	main(sys.argv)
